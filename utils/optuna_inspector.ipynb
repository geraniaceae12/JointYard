{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_parallel_coordinate,\n",
    "    plot_contour,\n",
    "    plot_slice,\n",
    "    plot_edf,\n",
    "    plot_rank,\n",
    "    plot_pareto_front\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì¶ 1. Study ÏÑ§Ï†ï Î∞è Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study Ï†ïÎ≥¥ ÏÑ§Ï†ï (Ïó¨Í∏∞Îßå ÏàòÏ†ï)\n",
    "study_name = \"vae_hparam_search\"  # <- Ïä§ÌÑ∞Îîî Ïù¥Î¶Ñ\n",
    "storage_path = \"sqlite:///path/to/your/optuna.db\"  # <- DB Í≤ΩÎ°ú\n",
    "\n",
    "# Study Î∂àÎü¨Ïò§Í∏∞\n",
    "study = optuna.load_study(study_name=study_name, storage=storage_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîç 2. Study Í∏∞Î≥∏ ÏöîÏïΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study ÏöîÏïΩ\n",
    "print(f\"üìä Study name: {study.study_name}\")\n",
    "print(f\"‚úÖ Number of trials: {len(study.trials)}\")\n",
    "print(f\"üéØ Optimization directions: {study.directions}\")\n",
    "\n",
    "is_multiobjective = len(study.directions) > 1\n",
    "print(f\"üéØ Multi-objective study: {is_multiobjective}\")\n",
    "\n",
    "if not is_multiobjective:\n",
    "    best = study.best_trial\n",
    "    print(f\"ü•á Best trial (ID: {best.number}) - Objectives: {best.value}\")\n",
    "    for key, value in best.params.items():\n",
    "        print(f\"  - {key}: {value}\")\n",
    "else:\n",
    "    print(\"üåü Multi-objective study: showing Pareto-optimal trials\")\n",
    "    pareto_trials = study.best_trials\n",
    "    for i, trial in enumerate(pareto_trials):\n",
    "        print(f\"Trial {trial.number} - Objectives: {trial.values}\")\n",
    "        for key, value in trial.params.items():\n",
    "            print(f\"  - {key}: {value}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìã 3. Í∞ÑÏÜåÌôîÎêú Trials Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Î≥¥Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏõêÌïòÎäî ÌïÑÎìúÎßå ÌëúÏãú\n",
    "df_simple = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\n",
    "df_simple.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üíæ 4. Trial Îç∞Ïù¥ÌÑ∞ CSVÎ°ú Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials = study.trials_dataframe()\n",
    "df_trials.to_csv(\"optuna_trials_export.csv\", index=False)\n",
    "print(\"üìÅ Trials exported to optuna_trials_export.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùó 5. Ïã§Ìå®Ìïú Trial Î°úÍ∑∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_trials = [t for t in study.trials if t.state.name != \"COMPLETE\"]\n",
    "print(f\"‚ùó Failed trials: {len(failed_trials)}\")\n",
    "\n",
    "for trial in failed_trials:\n",
    "    print(f\"Trial {trial.number} failed with state: {trial.state.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìà 6. Îã®Ïùº Î™©Ï†Å/Îã§Î™©Ï†Å Í≥µÌÜµ ÏãúÍ∞ÅÌôî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_optimization_history, plot_param_importances\n",
    "if is_multiobjective:\n",
    "    for i in range(len(study.directions)):\n",
    "        print(f\"\\nüéØ Objective {i} Optimization History\")\n",
    "        try:\n",
    "            plot_optimization_history(study, target=lambda t: t.values[i], target_name=f\"Objective {i}\").show()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è plot_optimization_history for Objective {i} failed:\", e)\n",
    "\n",
    "        print(f\"\\nüéØ Objective {i} Param Importances\")\n",
    "        try:\n",
    "            plot_param_importances(study, target=lambda t: t.values[i], target_name=f\"Objective {i}\").show()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è plot_param_importances for Objective {i} failed:\", e)\n",
    "else:\n",
    "    plot_optimization_history(study).show()\n",
    "    plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_parallel_coordinate, plot_contour, plot_slice\n",
    "if is_multiobjective:\n",
    "    for i in range(len(study.directions)):\n",
    "        print(f\"\\nüéØ Parallel Coordinate Plot for Objective {i}\")\n",
    "        plot_parallel_coordinate(\n",
    "            study, target=lambda t: t.values[i], target_name=f\"Objective {i}\"\n",
    "        ).show()\n",
    "\n",
    "        print(f\"\\nüéØ Contour Plot for Objective {i}\")\n",
    "        plot_contour(\n",
    "            study, target=lambda t: t.values[i], target_name=f\"Objective {i}\"\n",
    "        ).show()\n",
    "\n",
    "        print(f\"\\nüéØ Slice Plot for Objective {i}\")\n",
    "        plot_slice(\n",
    "            study, target=lambda t: t.values[i], target_name=f\"Objective {i}\"\n",
    "        ).show()\n",
    "else:\n",
    "    plot_parallel_coordinate(study).show()\n",
    "    plot_contour(study).show()\n",
    "    plot_slice(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDF: Empirical Distribution Function plot & Rank plot\n",
    "if is_multiobjective:\n",
    "    for i in range(len(study.directions)):\n",
    "        print(f\"\\nüìà EDF for Objective {i}\")\n",
    "        plot_edf(\n",
    "            study,\n",
    "            target=lambda t: t.values[i],\n",
    "            target_name=f\"Objective {i}\"\n",
    "        ).show()\n",
    "\n",
    "        print(f\"üìä Rank plot for Objective {i}\")\n",
    "        plot_rank(\n",
    "            study,\n",
    "            target=lambda t: t.values[i],\n",
    "            target_name=f\"Objective {i}\"\n",
    "        ).show()\n",
    "else:\n",
    "    print(\"\\nüìà EDF (Single Objective)\")\n",
    "    plot_edf(study).show()\n",
    "\n",
    "    print(\"üìä Rank plot (Single Objective)\")\n",
    "    plot_rank(study).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üåê 7. Pareto Front ÏãúÍ∞ÅÌôî (2DÎßå ÏßÄÏõê)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_multiobjective and len(study.directions) == 2 and len(pareto_trials) > 0:\n",
    "    pareto_df = pd.DataFrame([trial.values for trial in pareto_trials], columns=[\"Objective 1\", \"Objective 2\"])\n",
    "    pareto_df[\"Trial\"] = [t.number for t in pareto_trials]\n",
    "\n",
    "    fig = px.scatter(\n",
    "        pareto_df,\n",
    "        x=\"Objective 1\",\n",
    "        y=\"Objective 2\",\n",
    "        text=\"Trial\",\n",
    "        title=\"Pareto Front (2D)\",\n",
    "        labels={\"Objective 1\": \"Objective 1\", \"Objective 2\": \"Objective 2\"}\n",
    "    )\n",
    "    fig.update_traces(textposition='top center')\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pareto front plotting is currently supported only for 2 objectives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìä 8. Pareto Front Í∞Ñ ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ Î∂ÑÏÑù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_multiobjective and len(study.directions) == 2 and len(pareto_trials) > 0:\n",
    "    pareto_df_full = pd.DataFrame([trial.values for trial in pareto_trials])\n",
    "    pareto_df_full.columns = [f\"Objective {i+1}\" for i in range(len(study.directions))]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(pareto_df_full.corr(), annot=True, cmap=\"coolwarm\")\n",
    "    plt.title(\"Correlation between Objectives (Pareto Trials)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå 9. Pareto Front ÏãúÍ∞ÅÌôî (Optuna Í∏∞Î≥∏ Ï†úÍ≥µ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(study.directions) in [2, 3]:\n",
    "    try:\n",
    "        plot_pareto_front(study).show()\n",
    "    except Exception as e:\n",
    "        print(\"Pareto front plot failed:\", e)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è plot_pareto_front only supports 2 or 3 objectives.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postpose2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
